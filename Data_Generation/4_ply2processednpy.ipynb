{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T20:33:35.543132Z",
     "start_time": "2019-11-28T20:33:34.279041Z"
    }
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "import open3d as o3d\n",
    "import gc\n",
    "import zipfile\n",
    "from multiprocessing import Pool, cpu_count\n",
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Paths and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T20:33:35.548207Z",
     "start_time": "2019-11-28T20:33:35.545074Z"
    }
   },
   "outputs": [],
   "source": [
    "# pcd_folder='/home/sabyasachi/Projects/ati/data/data/datasets/Carla/lidarParam1/pair_corrupt/dynamic/'\n",
    "# npy_folder='/home/sabyasachi/Projects/ati/data/data/datasets/Carla/lidarParam1/pair_corrupt/dynamic_NPY/'\n",
    "\n",
    "BASE_PATH = '/home/sabyasachi/Projects/ati/data/data/datasets/Carla/64beam-Data'\n",
    "PAIR_FOLDER = \"pair\"\n",
    "# Do for both\n",
    "PCD_FOLDER = \"static\"\n",
    "# PCD_FOLDER = \"dynamic\"\n",
    "EXTRACTED_ARRAY_FNAME = \"arr_0.npy\"\n",
    "\n",
    "# BATCH_SIZE = 44000\n",
    "BATCH_SIZE = 2048\n",
    "RANGE_IMAGE_HEIGHT = 64\n",
    "RANGE_IMAGE_WIDTH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T20:33:35.558542Z",
     "start_time": "2019-11-28T20:33:35.550201Z"
    }
   },
   "outputs": [],
   "source": [
    "PCD_PATH = os.path.join(BASE_PATH, PAIR_FOLDER, PCD_FOLDER)\n",
    "if not os.path.exists(PCD_PATH):\n",
    "    print(\"Did not find : {}\".format(PCD_PATH))\n",
    "\n",
    "INITIAL_NPY_FOLDER = PCD_FOLDER + \"_begin_npy\"\n",
    "INITIAL_NPY_PATH = os.path.join(BASE_PATH, PAIR_FOLDER, INITIAL_NPY_FOLDER)\n",
    "if not os.path.exists(INITIAL_NPY_PATH):\n",
    "    os.makedirs(INITIAL_NPY_PATH)\n",
    "else:\n",
    "    shutil.rmtree(INITIAL_NPY_PATH)\n",
    "    os.makedirs(INITIAL_NPY_PATH)\n",
    "\n",
    "NPZ_FOLDER = PCD_FOLDER + \"_npz\"\n",
    "NPZ_PATH = os.path.join(BASE_PATH, PAIR_FOLDER, NPZ_FOLDER)\n",
    "if not os.path.exists(NPZ_PATH):\n",
    "    os.makedirs(NPZ_PATH)\n",
    "else:\n",
    "    shutil.rmtree(NPZ_PATH)\n",
    "    os.makedirs(NPZ_PATH)\n",
    "\n",
    "OUT_NPY_FOLDER = PCD_FOLDER + \"_out_npy\"\n",
    "OUT_NPY_PATH = os.path.join(BASE_PATH, PAIR_FOLDER, OUT_NPY_FOLDER)\n",
    "if not os.path.exists(OUT_NPY_PATH):\n",
    "    os.makedirs(OUT_NPY_PATH)\n",
    "else:\n",
    "    shutil.rmtree(OUT_NPY_PATH)\n",
    "    os.makedirs(OUT_NPY_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing functions from the paper source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T20:33:35.588612Z",
     "start_time": "2019-11-28T20:33:35.560770Z"
    },
    "code_folding": [
     0,
     13,
     20,
     65
    ]
   },
   "outputs": [],
   "source": [
    "def get_quadrant(point):\n",
    "    if point[0] >= 0. and point[1] >= 0. :\n",
    "        return 0\n",
    "    elif point[0] <= 0. and point[1] >= 0. : \n",
    "        return 1\n",
    "    elif point[0] <= 0. and point[1] <= 0. : \n",
    "        return 2\n",
    "    elif point[0] >= 0. and point[1] <= 0. : \n",
    "        return 3\n",
    "    else :\n",
    "        raise Exception('invalid input %s', point) \n",
    "\n",
    "\n",
    "def passed_origin(x_t, x_t1):\n",
    "    if get_quadrant(x_t1) == 3 and get_quadrant(x_t) == 0: \n",
    "        return True\n",
    "    else : \n",
    "        return False\n",
    "\n",
    "\n",
    "def fit_quadrant(points, quadrant, desired_amt):\n",
    "    \n",
    "    \n",
    "    points = np.asarray(points)\n",
    "    slots = []\n",
    "    slot_size = np.pi / (2 * desired_amt)\n",
    "    for i in range(int(desired_amt)) : slots.append([])\n",
    "    if quadrant == 0: \n",
    "        points = points[::-1]\n",
    "    elif quadrant == 1 : \n",
    "        points[:, 0] = - points[:, 0]\n",
    "    elif quadrant == 2 :\n",
    "        points = points[::-1] \n",
    "        points[:, 0] = - points[:, 0]\n",
    "        points[:, 1] = - points[:, 1]\n",
    "    elif quadrant == 3 : \n",
    "        points[:, 1] = - points[:, 1]\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "    for point in points :\n",
    "        angle = np.arctan(point[1] / (point[0]+0.000001))\n",
    "        index = min(int(angle / slot_size), desired_amt - 1)\n",
    "        slots[int(index)].append(point)\n",
    "\n",
    "    for i in range(len(slots)):\n",
    "        if len(slots[i]) == 0 : \n",
    "            slots[i] = np.array([0., 0., 0., 0.])\n",
    "        else :\n",
    "            full_slot = np.asarray(slots[i])\n",
    "            slots[i] = full_slot.mean(axis=0)\n",
    "\n",
    "    points = np.asarray(slots)\n",
    "    if quadrant == 0: \n",
    "        points = points[::-1]\n",
    "    elif quadrant == 1 : \n",
    "        points[:, 0] = - points[:, 0]\n",
    "    elif quadrant == 2 : \n",
    "        points = points[::-1]\n",
    "        points[:, 0] = - points[:, 0]\n",
    "        points[:, 1] = - points[:, 1]\n",
    "    elif quadrant == 3 : \n",
    "        points[:, 1] = - points[:, 1]\n",
    "\n",
    "    return points\n",
    "\n",
    "def parse_velo(velo):\n",
    "    # points closer to the origin (0,0,0) are at the end of the point cloud.\n",
    "    # invert the point cloud such that we begin near the origin. \n",
    "    \n",
    "    # returns: a H x 4 x ? array, split into quadrants\n",
    "    velo = velo[::-1]\n",
    "    lines = []\n",
    "    current_point = velo[0]\n",
    "    current_quadrant = get_quadrant(current_point)\n",
    "    current_line = [[], [], [], []]\n",
    "    quadrant_switches = 0\n",
    "    for point in velo :\n",
    "        point_quadrant = get_quadrant(point)\n",
    "        \n",
    "        if passed_origin(current_point, point):\n",
    "            lines.append(current_line)\n",
    "            current_line = [[], [], [], []]\n",
    "\n",
    "        current_line[point_quadrant].append(point)\n",
    "        current_quadrant = point_quadrant\n",
    "        current_point = point\n",
    "\n",
    "    return lines\n",
    "\n",
    "\n",
    "def setmatch(lines,lenLines):\n",
    "    arr=[[np.array([0,0,0,0]),np.array([0,0,0,0])]]\n",
    "    if len(lines) > lenLines:\n",
    "        return lines[:lenLines]\n",
    "    else:\n",
    "        for i in range(abs(len(lines)-lenLines)):\n",
    "            lines.append(arr)\n",
    "    return lines\n",
    "\n",
    "def process_velo(velo, points_per_layer, stop=False):\n",
    "    \n",
    "    lenLines=RANGE_IMAGE_HEIGHT\n",
    "    lines = parse_velo(velo)\n",
    "    inverse = quad_to_pc_inv(lines)\n",
    "    lines = lines[2:-1]\n",
    "#     print(lines[])\n",
    "#     print((lines[0]))\n",
    "#     raise SystemError\n",
    "    if(len(lines)!=lenLines):\n",
    "        lines=setmatch(lines,lenLines)\n",
    "#     print(len(lines), flush=True)\n",
    "    if len(lines) != RANGE_IMAGE_HEIGHT : raise Exception('invalid nb un of lines')\n",
    "    out_tensor = np.zeros((RANGE_IMAGE_HEIGHT, points_per_layer, 4))\n",
    "    if stop:\n",
    "        import pdb; pdb.set_trace()\n",
    "        x = 1\n",
    "    for j in range(len(lines)):\n",
    "        line = lines[j]\n",
    "        out_line = np.zeros((points_per_layer, 4))\n",
    "        for i in range(len(line)):\n",
    "            if(len(line[i])==0):\n",
    "                line[i]=[np.array([0.0,0.0,0.0,0.0])]\n",
    "            gridded = fit_quadrant(line[i], i, points_per_layer / 4)\n",
    "            out_tensor[j][i*int(points_per_layer/4):(i+1)*int(points_per_layer/4), :] = gridded[::-1]\n",
    "\n",
    "    return out_tensor, inverse\n",
    "\n",
    "\n",
    "def quad_to_pc_inv(lines, th=3.):\n",
    "    # lines is a 63 x 4 array, where each slot has an array of 4d/3d points\n",
    "    # goal : get an array of points that fills empty spaces\n",
    "    points = []\n",
    "    for i in range(len(lines)) :\n",
    "        line = lines[i] \n",
    "        distance = []\n",
    "        for quad in line : \n",
    "            for point in quad : \n",
    "                x, y, z = point[:3]\n",
    "                distance.append(x**2 + y**2)\n",
    "        distance = np.array(distance)\n",
    "        std = distance.std()\n",
    "        sorted_indices = np.argsort(distance)\n",
    "        median_index = sorted_indices[int(sorted_indices.shape[0]*0.95)]\n",
    "        median = distance[median_index]\n",
    "\n",
    "        for quad in line : \n",
    "            for point in quad : \n",
    "                x, y, z = point[:3]\n",
    "                dist = x ** 2 + y ** 2 \n",
    "                if dist < median and (median/dist-1.) > th:#*std : \n",
    "                    # blocked point --> scale to get real pt\n",
    "                    scale = np.sqrt(median / dist)\n",
    "                    scaled = scale * point\n",
    "                    points.append(scaled)\n",
    "\n",
    "\n",
    "    return np.array(points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T20:33:35.595842Z",
     "start_time": "2019-11-28T20:33:35.591723Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def getint(name):\n",
    "    return int(name.split('.')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCD to NPY files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T20:33:35.605229Z",
     "start_time": "2019-11-28T20:33:35.598804Z"
    }
   },
   "outputs": [],
   "source": [
    "def parallel_pcd2begin_npy(pcd_fname):\n",
    "    pcd_file_path = os.path.join(PCD_PATH, pcd_fname)\n",
    "    pcd = o3d.read_point_cloud(pcd_file_path)\n",
    "    pcd_arr = np.asarray(pcd.points)\n",
    "    pcd_arr = np.append(pcd_arr, np.zeros((pcd_arr.shape[0],1)), axis=1)\n",
    "    \n",
    "    npy_fname = pcd_fname[:-4] + \".npy\"\n",
    "    npy_file_path = os.path.join(INITIAL_NPY_PATH, npy_fname)\n",
    "    pcd_arr.dump(open(npy_file_path, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T20:37:20.321290Z",
     "start_time": "2019-11-28T20:33:35.606786Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "829de852d6564728956e729574bc78bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=9395), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_npy_args = sorted(os.listdir(PCD_PATH), key=getint)\n",
    "process_npy_pool = Pool(cpu_count()-1)\n",
    "__ = [each for each in tqdm_notebook(process_npy_pool.imap(parallel_pcd2begin_npy,\n",
    "                                                       parallel_npy_args),\n",
    "                                     total = len(parallel_npy_args))]\n",
    "process_npy_pool.terminate()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NPY to NPZ files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T20:37:20.326391Z",
     "start_time": "2019-11-28T20:37:20.323019Z"
    }
   },
   "outputs": [],
   "source": [
    "def parallel_npy2processed(npy_file):\n",
    "    gc.collect()\n",
    "    npy_file_path = os.path.join(INITIAL_NPY_PATH, npy_file)\n",
    "    raw_lidar = np.load(npy_file_path, allow_pickle=True)\n",
    "    processed_lidar, _ = process_velo(raw_lidar, RANGE_IMAGE_WIDTH)\n",
    "    return processed_lidar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T20:37:23.021267Z",
     "start_time": "2019-11-28T20:37:20.328565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "npy_folder_size = len(os.listdir(INITIAL_NPY_PATH))\n",
    "leftout_size = npy_folder_size % BATCH_SIZE\n",
    "n_batches = int(npy_folder_size / BATCH_SIZE)\n",
    "file_list = sorted(os.listdir(INITIAL_NPY_PATH), key=getint)\n",
    "full_npy_file_list = np.split(np.array(file_list)[:-leftout_size], n_batches)\n",
    "# To consider last small batch\n",
    "full_npy_file_list += [np.array(file_list[-leftout_size:])]\n",
    "\n",
    "print(len(full_npy_file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T20:54:43.162866Z",
     "start_time": "2019-11-28T20:37:23.023232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4bfa280e16949c681dbee63a72a9a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2048), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "npz_file_idx = 0\n",
    "for some_npy_file_list in full_npy_file_list:\n",
    "    print(len(some_npy_file_list))\n",
    "    parallel_processed_args = some_npy_file_list\n",
    "    process_processed_pool = Pool(cpu_count()-1)\n",
    "    one_run_npy_file = [each for each in tqdm_notebook(process_processed_pool.imap(parallel_npy2processed,\n",
    "                                                           parallel_processed_args), total=len(parallel_processed_args))]\n",
    "    process_processed_pool.terminate()\n",
    "    gc.collect()\n",
    "    \n",
    "    npz_file_path = os.path.join(NPZ_PATH, str(npz_file_idx))\n",
    "    np.savez(npz_file_path, one_run_npy_file)\n",
    "    npz_file_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NPZ extracted serially to NPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T20:59:49.690367Z",
     "start_time": "2019-11-28T20:54:43.164798Z"
    }
   },
   "outputs": [],
   "source": [
    "for npz_fname in tqdm_notebook(sorted(os.listdir(NPZ_PATH), key=getint)):\n",
    "    npz_path = os.path.join(NPZ_PATH, npz_fname)\n",
    "    with zipfile.ZipFile(npz_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(OUT_NPY_PATH)\n",
    "    \n",
    "    out_npy_fname = npz_fname[:-4] + \".npy\"\n",
    "    src_fname = os.path.join(OUT_NPY_PATH, EXTRACTED_ARRAY_FNAME)\n",
    "    dst_fname = os.path.join(OUT_NPY_PATH, out_npy_fname)\n",
    "    os.rename(src_fname, dst_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
